{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NvvmError",
     "evalue": "Failed to compile\n\nIR version 1.6 incompatible with current version 2.0\n<unnamed>: error: incompatible IR detected. Possible mix of compiler/IR from different releases.\nNVVM_ERROR_IR_VERSION_MISMATCH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNvvmError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-59c4907e69b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../../dysts/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdysts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdysts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdysts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/home_carnot/hideaki/lab/christian/240827_reproducibility/dysts/benchmarks/../../dysts/dysts/datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimpute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tsfresh/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m from tsfresh.convenience.relevant_extraction import (  # noqa: E402\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mextract_relevant_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tsfresh/convenience/relevant_extraction.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from tsfresh.utilities.dataframe_functions import (\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tsfresh/feature_extraction/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m from tsfresh.feature_extraction.settings import (\n\u001b[1;32m      7\u001b[0m     \u001b[0mComprehensiveFCParameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tsfresh/feature_extraction/extraction.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_calculators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_tsdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsfresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComprehensiveFCParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tsfresh/feature_extraction/feature_calculators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatrixprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoSolutionPossible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/stumpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgpu_stump\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpu_stump\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgpu_aamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpu_aamp\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgpu_ostinato\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpu_ostinato\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/stumpy/gpu_stump.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgpu_aamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpu_aamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/stumpy/gpu_aamp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m @cuda.jit(\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;34m\"(i8, f8[:], f8[:], i8, f8[:], f8[:], f8[:], b1[:], b1[:],\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"f8[:], f8[:], i8, b1, i8, f8[:, :], i8[:, :], b1)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/decorators.py\u001b[0m in \u001b[0;36m_jit\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mtargetoptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fastmath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfastmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mtargetoptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc_or_sig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetoptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, py_func, sigs, targetoptions)\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Compilation disabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             kernel = _Kernel(self.py_func, argtypes, link=self.link,\n\u001b[0;32m-> 1087\u001b[0;31m                              **self.targetoptions)\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;31m# Inspired by _DispatcherBase.add_overload, but differs slightly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;31m# because we're inserting a _Kernel object instead of a compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# A kernel needs cooperative launch if grid_sync is being used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcooperative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cudaCGGetIntrinsicHandle'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_asm_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;31m# We need to link against cudadevrt if grid sync is being used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcooperative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_asm_str\u001b[0;34m(self, cc)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_asm_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_join_ptxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ptxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ptxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/codegen.py\u001b[0m in \u001b[0;36m_get_ptxes\u001b[0;34m(self, cc)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Otherwise, we compile all modules with NVVM at once because this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# results in better optimization than separate compilation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mptxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnvvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllvm_to_ptx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Sometimes the result from NVVM contains trailing whitespace and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/cudadrv/nvvm.py\u001b[0m in \u001b[0;36mllvm_to_ptx\u001b[0;34m(llvmir, **opts)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0mcu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_add_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/cudadrv/nvvm.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, **options)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                           for x in opts])\n\u001b[1;32m    296\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvvmCompileProgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Failed to compile\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# get result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/cudadrv/nvvm.py\u001b[0m in \u001b[0;36m_try_error\u001b[0;34m(self, err, msg)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/site-packages/numba/cuda/cudadrv/nvvm.py\u001b[0m in \u001b[0;36mcheck_error\u001b[0;34m(self, error, msg, exit)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNvvmError\u001b[0m: Failed to compile\n\nIR version 1.6 incompatible with current version 2.0\n<unnamed>: error: incompatible IR detected. Possible mix of compiler/IR from different releases.\nNVVM_ERROR_IR_VERSION_MISMATCH"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "import pandas as pd\n",
    "\n",
    "# import dysts\n",
    "sys.path.append(os.path.join(os.getcwd(),'../../darts/'))\n",
    "import darts\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(),'../../dysts/'))\n",
    "from dysts.datasets import *\n",
    "from dysts.flows import *\n",
    "from dysts.base import *\n",
    "from dysts.utils import *\n",
    "from dysts.analysis import *\n",
    "\n",
    "#import degas as dg\n",
    "#dg.set_style()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# python3 find_hyperparameters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and record forecasts on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out output --err error\n",
    "\n",
    "# python3 compute_benchmarks.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Forecasting Benchmark Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "GRANULARITY = 100\n",
    "DATE = 221025 # noise level 0.8, not including RBF\n",
    "#DATE = 220812 # noise level 0.2, not including RBF\n",
    "\n",
    "#/results/221025_results_test_univariate__pts_per_period_ # large noise \n",
    "#/results/220812_results_test_univariate__pts_per_period_ # small noise \n",
    "\n",
    "#220315_results_test_univariate__pts_per_period_ #Initial try\n",
    "#220326_results_test_univariate__pts_per_period_\n",
    "#/results/220426_results_test_univariate__pts_per_period_\n",
    "\n",
    "with open(\n",
    "    os.getcwd()\n",
    "    + \"/results/\" + str(DATE) + \"_results_test_univariate__pts_per_period_\" + str(GRANULARITY) \n",
    "    + \"__periods_12_noise.json\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    all_results = json.load(file)\n",
    "\n",
    "#220428\n",
    "# with open(os.getcwd() + \"/results/results_test_univariate__pts_per_period_15__periods_12_noise.json\", \"r\") as file:\n",
    "#     all_results = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "## Convert R2 into a distance\n",
    "all_r2 = list()\n",
    "for equation_name in all_results:\n",
    "    for model_name in all_results[equation_name]:\n",
    "        if model_name == \"values\":\n",
    "            continue            \n",
    "        else:\n",
    "            ## convert r2 to a pseudodistance\n",
    "            all_results[equation_name][model_name][\"r2_score\"] = (\n",
    "                1 - all_results[equation_name][model_name][\"r2_score\"]\n",
    "            )\n",
    "\n",
    "            ## Coefficient of variation must be normed\n",
    "            all_results[equation_name][model_name][\"coefficient_of_variation\"] = np.abs(\n",
    "                all_results[equation_name][model_name][\"coefficient_of_variation\"]\n",
    "            )\n",
    "\n",
    "            ## Drop RMSE because it overlaps with MSE\n",
    "            all_results[equation_name][model_name].pop(\"rmse\", None)\n",
    "\n",
    "# HS Remove unimportant methods\n",
    "for equation_name in all_results:\n",
    "    for model_name in ['FFT', 'FourTheta', 'AutoARIMA', 'LSS_Takens']:\n",
    "        #all_results[equation_name].pop(model_name, None)\n",
    "        del all_results[equation_name][model_name]\n",
    "\n",
    "# HS using local darts\n",
    "sys.path.append(os.path.join(os.getcwd(),'../../darts/'))\n",
    "import darts\n",
    "from darts import TimeSeries\n",
    "from darts.metrics import mae\n",
    "\n",
    "wrap_array = lambda x: TimeSeries.from_dataframe(pd.DataFrame(np.squeeze(np.array(x))))\n",
    "mae_func = lambda x, y: mae(wrap_array(x), wrap_array(y))\n",
    "\n",
    "\n",
    "## Calculate MASE\n",
    "for equation_name in all_results:\n",
    "    baseline_onestep = mae_func(\n",
    "        all_results[equation_name][\"values\"][1:],\n",
    "        all_results[equation_name][\"values\"][:-1],\n",
    "    )\n",
    "    for model_name in all_results[equation_name]:\n",
    "        if model_name == \"values\":\n",
    "            continue\n",
    "        else:\n",
    "            mae_val = all_results[equation_name][model_name][\"mae\"]\n",
    "            all_results[equation_name][model_name][\"mase\"] = mae_val / baseline_onestep\n",
    "\n",
    "## get best models\n",
    "all_best_models = list()\n",
    "for equation_name in all_results:\n",
    "    all_models = list()\n",
    "    all_smapes = list()\n",
    "    for model_name in all_results[equation_name]:\n",
    "        if model_name != \"values\":\n",
    "            all_models.append(model_name)\n",
    "            all_smapes.append(all_results[equation_name][model_name][\"smape\"])\n",
    "    all_best_models.append(all_models[np.argmin(all_smapes)])\n",
    "\n",
    "all_results_transposed = dict()\n",
    "for model_name in all_results[\"Lorenz\"]:\n",
    "    if model_name == \"values\":\n",
    "        continue\n",
    "    all_results_transposed[model_name] = dict()\n",
    "for equation_name in all_results:\n",
    "    for model_name in all_results[equation_name]:\n",
    "        if model_name == \"values\":\n",
    "            continue\n",
    "        all_results_transposed[model_name][equation_name] = all_results[equation_name][\n",
    "            model_name\n",
    "        ]\n",
    "\n",
    "\n",
    "hist_values = dict()\n",
    "for model_name in all_results_transposed:\n",
    "    smape_vals = list()\n",
    "    for key in all_results_transposed[model_name]:\n",
    "        smape_vals.append(all_results_transposed[model_name][key][\"smape\"])\n",
    "\n",
    "    hist_values[model_name] = smape_vals.copy()\n",
    "\n",
    "if GRANULARITY == 15:\n",
    "    hist_values_low = hist_values.copy()\n",
    "elif GRANULARITY == 100:\n",
    "    hist_values_high = hist_values.copy()\n",
    "else:\n",
    "    raise ValueError(\"Granularity must be 15 or 100 points per period.\")\n",
    "    \n",
    "\n",
    "    #/results/221025_results_test_univariate__pts_per_period_\n",
    "#/results/220812_results_test_univariate__pts_per_period_ # small noise \n",
    "\n",
    "if DATE == 220812:\n",
    "    hist_values_low = hist_values.copy()\n",
    "elif DATE == 221025:\n",
    "    hist_values_high = hist_values.copy()\n",
    "else:\n",
    "    raise ValueError(\"Granularity must be 15 or 100 points per period.\")\n",
    "\n",
    "\n",
    "all_metric_names = list(all_results_transposed[\"ARIMA\"][\"Aizawa\"].keys())\n",
    "all_metric_names.remove(\"prediction\")\n",
    "\n",
    "## Compute forecast metrics\n",
    "metric_records = dict()\n",
    "for metric_name in all_metric_names:\n",
    "    metric_records[metric_name] = list()\n",
    "for model_name in all_results_transposed:\n",
    "    for equation_name in all_results_transposed[model_name]:\n",
    "        for metric_name in all_metric_names:\n",
    "            metric_records[metric_name].append(\n",
    "                all_results_transposed[model_name][equation_name][metric_name]\n",
    "            )\n",
    "df_metrics = pd.DataFrame(metric_records)\n",
    "\n",
    "\n",
    "# df_metrics[\"coefficient_of_variation\"] = np.abs(df_metrics[\"coefficient_of_variation\"])\n",
    "# df_metrics = df_metrics.drop('rmse', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mathematical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dysts.flows\n",
    "\n",
    "max_lyap = list()\n",
    "best_scores = list()\n",
    "for equation_name in all_results:    \n",
    "    all_scores_per_equation = list()\n",
    "    for model_name in all_results[equation_name]:\n",
    "        if model_name == \"values\":\n",
    "            continue\n",
    "        all_scores_per_equation.append(all_results[equation_name][model_name][\"smape\"])\n",
    "    \n",
    "    best_scores.append(min(all_scores_per_equation))\n",
    "\n",
    "    eq = getattr(dysts.flows, equation_name)()\n",
    "    max_lyap.append(eq.maximum_lyapunov_estimated)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_records = dict()\n",
    "for model_name in all_results_transposed.keys():\n",
    "    model_records[model_name] = list()\n",
    "    \n",
    "for model_name in all_results_transposed:\n",
    "    for equation_name in all_results_transposed[model_name]:\n",
    "        model_records[model_name].append(all_results_transposed[model_name][equation_name][\"smape\"])    \n",
    "    \n",
    "df_models = pd.DataFrame(model_records)\n",
    "\n",
    "\n",
    "corr_array = np.array(df_models.corr(method='spearman'))\n",
    "np.fill_diagonal(corr_array, np.nan)\n",
    "\n",
    "df_models_sorted = df_models.iloc[:, np.argsort(np.nanmedian(corr_array, axis=0))[::-1]]\n",
    "df_models_sorted = df_models.iloc[:, np.argsort(np.nanmax(corr_array, axis=0))[::-1]]\n",
    "\n",
    "# df_models_sorted = df_models.iloc[:, sort_order]\n",
    "\n",
    "ax = sns.heatmap(df_models_sorted.corr(method='spearman'), cmap=\"mako\", vmin=0, vmax=1)\n",
    "ax.set_aspect('equal')\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# dg.better_savefig(\"../private_writing/fig_resources/model_correlation_map.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare forecasting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_array = np.array(df_metrics.corr(method='spearman'))\n",
    "np.fill_diagonal(corr_array, np.nan)\n",
    "\n",
    "metric_sort_inds = np.argsort(np.nanmedian(corr_array, axis=0))[::-1]\n",
    "metric_sort_inds = np.argsort(np.nanmax(corr_array, axis=0))[::-1]\n",
    "df_metrics_sorted = df_metrics.iloc[:, metric_sort_inds]\n",
    "\n",
    "\n",
    "ax = sns.heatmap(df_metrics_sorted.corr(method='spearman'), cmap=\"mako\", vmin=0, vmax=1)\n",
    "ax.set_aspect('equal')\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# dg.better_savefig(\"../private_writing/fig_resources/metric_map.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare forecasting results against mathematical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_metric = \"smape\"\n",
    "models_df = dict()\n",
    "metrics_df = dict()\n",
    "for equation_name in all_results:\n",
    "    models_df[equation_name] = dict()\n",
    "    metrics_df[equation_name] = dict()\n",
    "    for model_name in all_results[equation_name]:\n",
    "        if model_name == \"values\": continue\n",
    "        models_df[equation_name][model_name] = all_results[equation_name][model_name][chosen_metric]\n",
    "    \n",
    "        for metric_name in all_results[equation_name][\"ARIMA\"]:\n",
    "            if metric_name == \"prediction\": continue\n",
    "            metrics_df[equation_name][metric_name] = all_results[equation_name][\"NBEATSModel\"][metric_name]\n",
    "    \n",
    "    \n",
    "models_df = pd.DataFrame(models_df).transpose()\n",
    "metrics_df = pd.DataFrame(metrics_df).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dysts.flows\n",
    "\n",
    "attributes =  ['maximum_lyapunov_estimated', 'kaplan_yorke_dimension', 'multiscale_entropy', 'correlation_dimension']\n",
    "all_properties = dict()\n",
    "for equation_name in get_attractor_list():\n",
    "    if equation_name in ['GenesioTesi','Hadley','SprottD','StickSlipOscillator']:\n",
    "        continue\n",
    "    \n",
    "    eq = getattr(dysts.flows, equation_name)()\n",
    "    attr_vals = [getattr(eq, item, None) for item in attributes]\n",
    "    \n",
    "    all_properties[equation_name] = dict(zip(attributes, attr_vals))\n",
    "    \n",
    "all_properties = pd.DataFrame(all_properties).transpose().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr = pd.concat([metrics_df, all_properties], axis=1, keys=['metrics_df', 'all_properties']).corr(method=\"spearman\").loc['metrics_df', 'all_properties']\n",
    "math_sort_inds = np.argsort(np.max(cross_corr, axis=0))[::-1]\n",
    "\n",
    "ax = sns.heatmap(cross_corr.transpose().iloc[math_sort_inds, metric_sort_inds], cmap=\"mako\", vmin=0, vmax=1)\n",
    "ax.set_aspect(1)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# dg.better_savefig(\"../private_writing/fig_resources/metric_math.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr = pd.concat([models_df, all_properties], axis=1, keys=['models_df', 'all_properties']).corr(method=\"spearman\").loc['models_df', 'all_properties']\n",
    "math_sort_inds = np.argsort(np.max(cross_corr, axis=0))[::-1]\n",
    "\n",
    "ax = sns.heatmap(cross_corr.transpose().iloc[math_sort_inds][df_models_sorted.columns], cmap=\"mako\", vmin=0, vmax=1)\n",
    "ax.set_aspect(1)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# dg.better_savefig(\"../private_writing/fig_resources/models_math_corr.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Easiest and hardest systems\n",
    "print(\"Easiest systems: \", np.unique(models_df.idxmin(axis=0), return_counts=True))\n",
    "print(\"Hardest systems: \", np.unique(models_df.idxmax(axis=0), return_counts=True))\n",
    "\n",
    "\n",
    "all_median_names = list()\n",
    "for key in models_df.keys():\n",
    "    all_median_names.append(models_df[models_df[key] == models_df[key].quantile(interpolation='nearest')].index[0])\n",
    "    \n",
    "print(\"Middle systems: \", np.unique(all_median_names, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mirror_df(df, mirror_val=0):\n",
    "    \"\"\"\n",
    "    Create a mirrored augmented dataframe. Used\n",
    "    for setting the right boundary conditions on kernel \n",
    "    density plots\n",
    "    \"\"\"\n",
    "    if np.isscalar(mirror_val):\n",
    "        return pd.concat([df, mirror_val - df])\n",
    "    else:\n",
    "        all_out_df = [df]\n",
    "        for val in mirror_val:\n",
    "            all_out_df.append(val - df)\n",
    "        return pd.concat(all_out_df)\n",
    "    \n",
    "#dflo = pd.DataFrame.from_dict(hist_values_low) ##########Commented out! HS\n",
    "dflo = pd.DataFrame.from_dict(hist_values_high)\n",
    "dflo[\"Granularity\"] = \"Coarse\"\n",
    "\n",
    "dfhi = pd.DataFrame.from_dict(hist_values_high)\n",
    "dfhi[\"Granularity\"] = \"Fine\"\n",
    "#data = pd.merge(dflo, dfhi, how=\"outer\")\n",
    "data = pd.merge(dfhi, dflo, how=\"outer\")\n",
    "\n",
    "all_model_names = np.array(list(hist_values_high.keys()))\n",
    "all_medians = [np.median(hist_values_high[name]) for name in hist_values_high]\n",
    "all_means = [np.mean(hist_values_high[name]) for name in hist_values_high]\n",
    "#sort_order = np.argsort(all_medians)\n",
    "sort_order = np.argsort(all_means)\n",
    "\n",
    "data_long = pd.melt(data, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.gca()\n",
    "\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    hue=\"Granularity\",\n",
    "    order=all_model_names[sort_order],\n",
    "    linewidth=0,\n",
    "    size=3,\n",
    "    alpha=0.1,\n",
    "    split=True,\n",
    "    scale=\"area\",\n",
    "    inner=None,\n",
    "    palette=\"mako\",\n",
    ")\n",
    "ax = sns.pointplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    hue=\"Granularity\",\n",
    "    order=all_model_names[sort_order],\n",
    "    linewidth=0,\n",
    "    size=4,\n",
    "    palette={\"Coarse\": \"w\", \"Fine\": \"w\"},\n",
    "    join=False,\n",
    "    ci=99,\n",
    "    dodge=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "plt.ylim([0, 200])\n",
    "#dg.fixed_aspect_ratio(1 / 8)\n",
    "ax.grid(False)\n",
    "ax.legend_.remove()\n",
    "\n",
    "# dg.better_savefig(\"../private_writing/fig_resources/forecasting_violins.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dflo = pd.DataFrame.from_dict(hist_values_low) ##########Commented out! HS\n",
    "dflo = pd.DataFrame.from_dict(hist_values_high)\n",
    "dflo[\"Granularity\"] = \"Coarse\"\n",
    "\n",
    "dfhi = pd.DataFrame.from_dict(hist_values_high)\n",
    "dfhi[\"Granularity\"] = \"Fine\"\n",
    "#data = pd.merge(dflo, dfhi, how=\"outer\")\n",
    "data = pd.merge(dfhi, dflo, how=\"outer\")\n",
    "\n",
    "all_model_names = np.array(list(hist_values_high.keys()))\n",
    "all_medians = [np.median(hist_values_high[name]) for name in hist_values_high]\n",
    "all_means = [np.mean(hist_values_high[name]) for name in hist_values_high]\n",
    "#sort_order = np.argsort(all_medians)\n",
    "sort_order = np.argsort(all_means)\n",
    "\n",
    "#data_long = pd.melt(data, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")\n",
    "data_long = pd.melt(dfhi, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.gca()\n",
    "\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    order=all_model_names[sort_order],\n",
    "    #hue = ,\n",
    "    linewidth=0,\n",
    "    size=3,\n",
    "    alpha=0.1,\n",
    "    split=False,\n",
    "    scale=\"area\",\n",
    "    inner=None,\n",
    "    palette=\"flare_r\",\n",
    ")\n",
    "\n",
    "ax = sns.pointplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    order=all_model_names[sort_order],\n",
    "    linewidth=0,\n",
    "    size=4,\n",
    "    color = \"w\",\n",
    "    join=False,\n",
    "    ci=99,\n",
    "    dodge=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "plt.ylim([0, 200])\n",
    "#dg.fixed_aspect_ratio(1 / 8)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argsort(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median\n",
    "\n",
    "#dflo = pd.DataFrame.from_dict(hist_values_low) ##########Commented out! HS\n",
    "dflo = pd.DataFrame.from_dict(hist_values_high)\n",
    "dflo[\"Granularity\"] = \"Coarse\"\n",
    "\n",
    "dfhi = pd.DataFrame.from_dict(hist_values_high)\n",
    "dfhi[\"Granularity\"] = \"Fine\"\n",
    "#data = pd.merge(dflo, dfhi, how=\"outer\")\n",
    "data = pd.merge(dfhi, dflo, how=\"outer\")\n",
    "\n",
    "all_model_names = np.array(list(hist_values_high.keys()))\n",
    "all_medians = [np.median(hist_values_high[name]) for name in hist_values_high]\n",
    "all_means = [np.mean(hist_values_high[name]) for name in hist_values_high]\n",
    "#sort_order = np.argsort(all_medians)\n",
    "sort_order = np.argsort(all_means)\n",
    "\n",
    "#data_long = pd.melt(data, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")\n",
    "data_long = pd.melt(dfhi, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    order=all_model_names[sort_order],\n",
    "    #linewidth=0,\n",
    "    size=3,\n",
    "    alpha=0.1,\n",
    "    split=False,\n",
    "    scale=\"area\",\n",
    "    inner=\"quart\",\n",
    "    #palette=\"flare_r\",\n",
    ")\n",
    "\n",
    "ax = sns.pointplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    order=all_model_names[sort_order],\n",
    "    linewidth=0,\n",
    "    size=4,\n",
    "    color = \"w\",\n",
    "    join=False,\n",
    "    ci=0,\n",
    "    dodge=0.2,\n",
    "    estimator = np.mean,\n",
    ")\n",
    "\n",
    "\n",
    "plt.ylim([0, 250])\n",
    "#dg.fixed_aspect_ratio(1 / 8)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    data=data_long,\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    order=all_model_names[sort_order],\n",
    "    size=3,\n",
    "    alpha=0.1,\n",
    "    split=False,\n",
    "    scale=\"area\",\n",
    "    # inner=None,\n",
    "    inner=\"points\",\n",
    "    # palette=\"flare_r\",\n",
    ")\n",
    "\n",
    "plt.ylim([0, 200])\n",
    "#dg.fixed_aspect_ratio(1 / 8)\n",
    "#ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dflo = pd.DataFrame.from_dict(hist_values_low) ##########Commented out! HS\n",
    "# dflo = pd.DataFrame.from_dict(hist_values_high)\n",
    "# dflo[\"Granularity\"] = \"Coarse\"\n",
    "\n",
    "# dfhi = pd.DataFrame.from_dict(hist_values_high)\n",
    "# dfhi[\"Granularity\"] = \"Fine\"\n",
    "# #data = pd.merge(dflo, dfhi, how=\"outer\")\n",
    "# data = pd.merge(dfhi, dflo, how=\"outer\")\n",
    "\n",
    "# all_model_names = np.array(list(hist_values_low.keys()))\n",
    "# all_medians = [np.median(hist_values_low[name]) for name in hist_values_low]\n",
    "# all_means = [np.mean(hist_values_low[name]) for name in hist_values_low]\n",
    "# #sort_order = np.argsort(all_medians)\n",
    "# sort_order = np.argsort(all_means)\n",
    "\n",
    "# #data_long = pd.melt(data, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")\n",
    "# data_long = pd.melt(dflo, value_vars=all_model_names[sort_order], id_vars=\"Granularity\")\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# ax = plt.gca()\n",
    "\n",
    "\n",
    "# ax = sns.violinplot(\n",
    "#     data=data_long,\n",
    "#     x=\"variable\",\n",
    "#     y=\"value\",\n",
    "#     order=all_model_names[sort_order],\n",
    "#     linewidth=0,\n",
    "#     size=3,\n",
    "#     alpha=0.1,\n",
    "#     split=False,\n",
    "#     scale=\"area\",\n",
    "#     inner=None,\n",
    "#     palette=\"flare_r\",\n",
    "# )\n",
    "\n",
    "# ax = sns.pointplot(\n",
    "#     data=data_long,\n",
    "#     x=\"variable\",\n",
    "#     y=\"value\",\n",
    "#     order=all_model_names[sort_order],\n",
    "#     linewidth=0,\n",
    "#     size=4,\n",
    "#     color = \"w\",\n",
    "#     join=False,\n",
    "#     ci=99,\n",
    "#     dodge=0.2,\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.ylim([0, 200])\n",
    "# #dg.fixed_aspect_ratio(1 / 8)\n",
    "# ax.grid(False)\n",
    "\n",
    "# #https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group models by mathematical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_names = list(all_results.keys())\n",
    "model_names = list(all_results[equation_names[0]].keys())\n",
    "model_names.remove(\"values\")\n",
    "score_names = list(all_results[equation_names[0]][model_names[0]].keys())\n",
    "score_names.remove(\"prediction\")\n",
    "\n",
    "results_reduced = dict()\n",
    "for equation_name in equation_names:\n",
    "    if equation_name in ['GenesioTesi','Hadley','SprottD','StickSlipOscillator']:\n",
    "        continue\n",
    "    results_reduced[equation_name] = dict()\n",
    "    for model_name in model_names:\n",
    "        val = all_results[equation_name][model_name][\"smape\"]\n",
    "        results_reduced[equation_name][model_name] = val \n",
    "results_reduced = pd.DataFrame.from_dict(results_reduced)     \n",
    "results_reduced = results_reduced.iloc[sort_order] # sort by median error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sort_inds = all_properties.sort_values(by=\"maximum_lyapunov_estimated\").index\n",
    "\n",
    "color_list = sns.color_palette(\"husl\", results_reduced.shape[0])\n",
    "\n",
    "plt.figure()\n",
    "for clr, row in zip(color_list, results_reduced[sort_inds].to_numpy()):\n",
    "    plt.semilogx(\n",
    "        all_properties[\"maximum_lyapunov_estimated\"][sort_inds],\n",
    "        row,\n",
    "        color=clr\n",
    "    )\n",
    "plt.title(\"Score versus Lyapunov exponent\")\n",
    "\n",
    "\n",
    "\n",
    "sort_inds = all_properties.sort_values(by=\"correlation_dimension\").index\n",
    "\n",
    "plt.figure()\n",
    "for clr, row in zip(color_list, results_reduced[sort_inds].to_numpy()):\n",
    "    plt.plot(\n",
    "        all_properties[\"correlation_dimension\"][sort_inds],\n",
    "        row,\n",
    "        color=clr\n",
    "    )\n",
    "plt.title(\"Score versus correlation dimension\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for clr, row in zip(color_list, results_reduced[sort_inds].to_numpy()):\n",
    "    plt.plot(\n",
    "        all_properties[\"correlation_dimension\"][sort_inds],\n",
    "        row,\n",
    "        color=clr,\n",
    "        linewidth=4\n",
    "    )\n",
    "plt.legend(results_reduced.index, facecolor='white', framealpha=1, frameon=True)\n",
    "plt.title(\"Show legend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prop_name = \"correlation_dimension\"\n",
    "prop_name = \"maximum_lyapunov_estimated\"\n",
    "#prop_name = \"multiscale_entropy\"\n",
    "\n",
    "all_vals = list()\n",
    "vals = np.array(all_properties[prop_name])\n",
    "\n",
    "all_windows = list(zip(10 * np.arange(9), 10 * np.arange(2, 11)))\n",
    "\n",
    "for window in all_windows:\n",
    "    sel_inds = all_properties[prop_name][\n",
    "        all_properties[prop_name].between(\n",
    "            np.percentile(vals, window[0]), np.percentile(vals, window[1])\n",
    "        )\n",
    "    ].index\n",
    "    all_vals.append(results_reduced[sel_inds].median(axis=1))\n",
    "    \n",
    "plt.figure()\n",
    "for clr, row in zip(color_list, np.array(all_vals).T):\n",
    "    plt.plot(row, color=clr)\n",
    "#plt.ylim([0, 180])\n",
    "\n",
    "plt.legend(results_reduced.index, facecolor='white', framealpha=1, frameon=True)\n",
    "\n",
    "#dg.better_savefig(\"../private_writing/fig_resources/\" + prop_name + \"_ranks.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "plt.figure()\n",
    "for clr, row in zip(color_list, results_reduced[sort_inds].to_numpy()):\n",
    "    plt.plot(\n",
    "        all_properties[\"correlation_dimension\"][sort_inds],\n",
    "        row,\n",
    "        color=clr,\n",
    "        linewidth=4\n",
    "     )\n",
    "plt.legend(results_reduced.index, facecolor='white', framealpha=1, frameon=True)\n",
    "plt.title(\"Show legend\")\n",
    "\n",
    "# dg.better_savefig(\"../private_writing/fig_resources/lyap_legend.png\", dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7.9",
   "language": "python",
   "name": "python3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
